If you’ve been on or near the Generative AI (Gen AI) rollercoaster that has characterised the last year or so, it is likely you will have come across the acronym ‘RAG’. RAG stands for ‘Retrieval-Augmented Generation’. It is an approach commonly credited to a 2021 paper by a team led by researchers from Facebook AI Research (FAIR). This approach enables language models to generate ‘more specific, diverse and factual language’ than previously possible. Practically, this means that Large Language Model (LLM) driven systems using RAG are typically:

Less susceptible to hallucinations (e.g. factual errors)
Easily updated/extended to include new information (without retraining the LLM)
Able to provide references for their own factual statements
Additionally, the team claim that human evaluators involved in their research subjectively preferred RAG-powered LLM outputs over those without RAG. It is no surprise that with the explosion in Large Language Models (LLMs) like GPT-4, Claude and PaLM 2 in the last year, this method has rapidly become a standard tool in the LLM development toolbox.

This article aims to provide you with an accessible introduction to RAG. It’s aimed at getting ML practitioners up to speed with the basics, but if you’re semi-technical or simply curious about the world of Gen AI, you may find it useful too.